{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b36691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c0ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"ectreetoExtract.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dea1ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SrNo</th>\n",
       "      <th>Classname</th>\n",
       "      <th>subclassof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>677</td>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>carbon-monoxide dehydrogenase (cytochrome b-561)</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     SrNo                                         Classname  subclassof\n",
       "0  677  1.1.1.1  carbon-monoxide dehydrogenase (cytochrome b-561)         673"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230aba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ectree_list = []\n",
    "\n",
    "for i in range(len(dat)):\n",
    "    if(len(dat['SrNo'][i]) >= 7):\n",
    "        ectree_list.append(dat['SrNo'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1bcffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1.1\n"
     ]
    }
   ],
   "source": [
    "for ectree_str in range(len(ectree_list)):\n",
    "    print(ectree_list[ectree_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c999c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information on EC 1.1.1.1 - alcohol dehydrogenase\n",
      "CRYSTALLIZATION (Commentary)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\as787\\AppData\\Local\\Temp\\ipykernel_46464\\1375651691.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[new_columns[i]].iloc[[j]]= updated_final_link\n"
     ]
    }
   ],
   "source": [
    "for ectree_str in range(len(ectree_list)):\n",
    "    driver = webdriver.Chrome()\n",
    "    url = 'https://www.brenda-enzymes.org/enzyme.php?ecno=' + ectree_list[ectree_str]\n",
    "    driver.get(url)\n",
    "    #show all tables\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"flatnav_sa\"]').click()\n",
    "    title = driver.find_element(By.XPATH, '//*[@id=\"flatheader\"]/div/h1')\n",
    "    print(title.text)\n",
    "    # //*[@id=\"tab47\"] https://meet.google.com/csj-cxpp-ejv //*[@id=\"tab47\"]\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH, '//*[@id=\"tab5_head\"]/div[1]')\n",
    "        print(title.text)\n",
    "        chks = driver.find_elements(By.XPATH, \"//*[@id='tab5']//a[@href]\")\n",
    "\n",
    "        ent = 'entries'\n",
    "\n",
    "        for chk in chks:\n",
    "            txt = chk.text\n",
    "            if ent in txt:\n",
    "                chk.click()\n",
    "        tab1_eles = driver.find_elements(By.XPATH, '//div[@id=\"tab5\" and @class=\"equal\"]')\n",
    "        table_columns = []\n",
    "\n",
    "        for tab in tab1_eles:\n",
    "            \n",
    "            col_list = tab.find_elements(By.CLASS_NAME, 'header')\n",
    "            \n",
    "            for listss in col_list:\n",
    "                # print(listss.text)\n",
    "                table_columns.append(listss.text)\n",
    "        final_df = pd.DataFrame(columns = table_columns)\n",
    "        tab1_eles = driver.find_elements(By.XPATH, \"//div[contains(@id, 'tab5r') and contains(@class, 'cell')]\")\n",
    "        table_values = []\n",
    "        for tab in tab1_eles:\n",
    "            try:\n",
    "                link = tab.find_element(By.TAG_NAME, 'a')\n",
    "                temp_link = link.get_attribute('href')\n",
    "                \n",
    "                # if not('showRows' or 'hideRows') in temp_link:\n",
    "                if ('showRows' in temp_link or 'hideRows' in temp_link):\n",
    "                    #print(tab.text)\n",
    "                    table_values.append(tab.text)\n",
    "                    # print(tab.text + ', ' + temp_link)\n",
    "                    # table_values.append(tab.text + ',' + temp_link)\n",
    "                    \n",
    "                else:\n",
    "                    # print(tab.text)\n",
    "                    # table_values.append(tab.text)\n",
    "                    \n",
    "                    #print(tab.text + ', ' + temp_link)\n",
    "                    table_values.append(tab.text + ',' + temp_link)\n",
    "                    \n",
    "            except:\n",
    "                table_values.append(tab.text)\n",
    "                #print(tab.text)\n",
    "        for i in range(len(table_columns)):\n",
    "            temp_value = table_values[i::(len(table_columns))]\n",
    "            #print(temp_value)\n",
    "            \n",
    "            final_df[table_columns[i]] = temp_value\n",
    "        final_df.to_csv('table_for_test.csv')\n",
    "        final_df.replace(r'^\\s*$', np.nan, regex=True, inplace = True)\n",
    "        final_df.ffill(inplace = True)\n",
    "        http_columns = final_df.columns[final_df.apply(lambda x: x.str.contains(\"https\")).any()]\n",
    "        # len(http_columns)\n",
    "        # main_df = final_df.copy()\n",
    "        for i in range(len(http_columns)):\n",
    "            # print(http_columns[i])\n",
    "            temp_string = http_columns[i] + ' ' + 'href'\n",
    "            # new = final_df[http_columns[i]].str.split(\",\", n = 1, expand = True)\n",
    "            new = final_df[http_columns[i]].str.rsplit(\",\", n=1, expand = True)\n",
    "            # print(new[0])        \n",
    "            # print(new[1])\n",
    "            final_df[http_columns[i]] = new[0]\n",
    "            final_df[temp_string]= new[1] \n",
    "        final_df.head(20)\n",
    "        js_columns = final_df.columns[final_df.apply(lambda x: x.str.contains(\"javascript\")).any()]\n",
    "        new_columns = []\n",
    "\n",
    "        for i in range(len(js_columns)):\n",
    "            # print(js_columns[i])\n",
    "            temp_string = js_columns[i] + ' ' + 'href'\n",
    "            # new = final_df[js_columns[i]].str.split(\",\", n = 1, expand = True)\n",
    "            new = final_df[js_columns[i]].str.rsplit(\",\", n = 1, expand = True)\n",
    "                        \n",
    "            final_df[js_columns[i]] = new[0]\n",
    "            final_df[temp_string]= new[1] \n",
    "            \n",
    "            new_columns.append(temp_string)\n",
    "\n",
    "        # explode\n",
    "        if ('LITERATURE' in final_df or 'UNIPROT' in final_df):\n",
    "            final_df['LITERATURE'] = final_df['LITERATURE'].str.split(', ')\n",
    "            final_df = final_df.explode(['LITERATURE'])\n",
    "            \n",
    "            final_df['UNIPROT'] = final_df['UNIPROT'].str.split(', ')\n",
    "            final_df = final_df.explode(['UNIPROT'])\n",
    "        final_df = final_df.reset_index()\n",
    "        final_df.drop('index', axis = 1, inplace = True)\n",
    "        # final_df.tail()\n",
    "        # final_df['LITERATURE href'][0].split('&')[0] + '&r=' + final_df['LITERATURE'][0]\n",
    "        # literature_temp = 'https://www.brenda-enzymes.org/literature.php?e=1.1.1.1&r=285624'\n",
    "        final_df['LITERATURE href'] = \"https://www.brenda-enzymes.org/literature.php?e=1.1.1.1&r=737159\"\n",
    "        for i in range(len(final_df)):\n",
    "            try:\n",
    "                # ectra codes\n",
    "                if(final_df['LITERATURE'][i] != '-'):\n",
    "                    final_df['LITERATURE href'][i] = final_df['LITERATURE href'][i].split('&')[0] + '&r=' + final_df['LITERATURE'][i]\n",
    "                else:\n",
    "                    final_df['LITERATURE href'][i] = '-'\n",
    "            except:\n",
    "                continue\n",
    "        # final_df\n",
    "        temp_list_href = []\n",
    "        for i in range(len(new_columns)):\n",
    "            temp_list = final_df[new_columns[i]]\n",
    "            \n",
    "            headers = [item for item in temp_list if item is not None]\n",
    "            temp_list_href.append(headers[0])\n",
    "        temp_list_href = temp_list_href[:2]\n",
    "        resulted_link = ['https://www.brenda-enzymes.org/taxonomy.php?f[id][value]=1515','https://www.brenda-enzymes.org/sequences.php?AC=A3DCI2']\n",
    "        temp_df = final_df[new_columns]\n",
    "        for i in range(len(new_columns)):\n",
    "            # print(new_columns[i])\n",
    "            new_link = resulted_link[i]\n",
    "            \n",
    "            for j in range(len(temp_df)):\n",
    "                old_link = temp_df[new_columns[i]].iloc[[j]].values\n",
    "                \n",
    "                try:\n",
    "                    extracted_new_link_str = re.findall(r'\\b\\d+\\b', new_link)\n",
    "                    \n",
    "                    extracted_old_link_str = re.findall(r\"'(.*?)'\", old_link[0], re.DOTALL) \n",
    "                    \n",
    "                    if not extracted_new_link_str:\n",
    "                        extracted_new_link_str = new_link.split(\"=\",1)[1]\n",
    "                        updated_final_link = new_link.replace(str(extracted_new_link_str), str(extracted_old_link_str[0]))\n",
    "                    else:\n",
    "                        updated_final_link = new_link.replace(str(extracted_new_link_str[0]), str(extracted_old_link_str[0]))\n",
    "                        \n",
    "                    # print(f'old link: {old_link}')\n",
    "                    # print(f'extracted from old link: {extracted_old_link_str[0]}')\n",
    "                    # print(f'new link: {new_link}')\n",
    "                    # print(f'extracted from new link: {extracted_new_link_str[0]}') \n",
    "                    # \n",
    "                    # print(f'updated final link: {updated_final_link}')\n",
    "                    # print('\\n')\n",
    "                    \n",
    "                    temp_df[new_columns[i]].iloc[[j]]= updated_final_link\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "        for i in range(len(new_columns)):\n",
    "            final_df = final_df.drop(new_columns[i], axis = 1)\n",
    "        final_df = final_df.drop_duplicates()\n",
    "        diff = len(temp_df) - len(final_df)\n",
    "        final_df.tail()\n",
    "        temp_df.drop(temp_df.tail(diff).index,inplace = True)\n",
    "        len(temp_df)\n",
    "        frames = [final_df, temp_df]\n",
    "        final_df = pd.concat([final_df, temp_df], axis = 1)\n",
    "        final_df.head()\n",
    "        final_df.index = np.arange(1, len(final_df) + 1)\n",
    "        final_df.insert(loc = 0,column = 'id',value = final_df.index)\n",
    "        final_df.insert(loc = 1,column = 'ectree',value = ectree_list[ectree_str])\n",
    "        final_df.replace(to_replace=[None], value='-', inplace=True)\n",
    "        final_df.columns = [c.replace(\" \", \"_\") for c in final_df.columns]\n",
    "        final_df.columns = [c.replace(\"(\", \"\") for c in final_df.columns]\n",
    "        final_df.columns = [c.replace(\")\", \"\") for c in final_df.columns]\n",
    "        final_df.columns = [c.replace(\"?\", \"\") for c in final_df.columns]\n",
    "        final_df.columns = [c.replace(\"=\", \"_equals_\") for c in final_df.columns]\n",
    "        final_df = final_df.replace('', np.NaN)\n",
    "        final_df.ffill(inplace = True)\n",
    "        \n",
    "        final_df['LITERATURE_href'] = final_df['LITERATURE_href'].replace(\"1.1.1.1\", ectree_list[ectree_str], regex = True)\n",
    "        #### reaction_diagram process\n",
    "        driver.quit()\n",
    "        #### Writing on mysql\n",
    "        import mysql.connector\n",
    "        mydb = mysql.connector.connect(host = 'quantumzyme.com', user = 'zummit_user', password = 'kZf-ih&[xV@2', database = 'qzBrenda', use_pure = True)\n",
    "        # mydb = mysql.connector.connect(host = 'localhost', user = 'root', password = 'Darshini1@*',port = 3306, database = 'brenda', use_pure = True)\n",
    "        \n",
    "        #### create table string \n",
    "        final_df.drop('id', axis = 1, inplace = True)\n",
    "        combined_string = []\n",
    "        for i in range(len(final_df.columns)):\n",
    "            if(len(final_df.columns[i]) <= 64):\n",
    "                temp_string = final_df.columns[i] + ' VARCHAR(500)'\n",
    "                combined_string.append(temp_string) \n",
    "            else:\n",
    "                temp_string = final_df.columns[i][0:63] + ' VARCHAR(500)'\n",
    "                combined_string.append(temp_string)\n",
    "            \n",
    "        combined_string_new = ', '.join(combined_string)\n",
    "        #print(combined_string_new)\n",
    "        #print('\\n')\n",
    "\n",
    "        create_table_string = 'CREATE TABLE IF NOT EXISTS '+ final_df.columns[1] + '(id int NOT NULL AUTO_INCREMENT, ' + combined_string_new + ', PRIMARY KEY (id))'\n",
    "        #print(create_table_string)\n",
    "        mycursor = mydb.cursor()\n",
    "        try:\n",
    "            mycursor.execute(create_table_string)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        #### insert into table\n",
    "        combined_insert_string = []\n",
    "        percent_s = []\n",
    "        percent = '%s'\n",
    "        for i in range(len(final_df.columns)):\n",
    "            if(len(final_df.columns[i]) >= 64):\n",
    "                combined_insert_string.append(final_df.columns[i][0:63])\n",
    "                percent_s.append(percent)\n",
    "\n",
    "            else:\n",
    "                combined_insert_string.append(final_df.columns[i])\n",
    "                percent_s.append(percent)\n",
    "\n",
    "        #print(i)\n",
    "        # percent_s = percent_s[:-1]\n",
    "        percent_s = ', '.join(percent_s)\n",
    "\n",
    "        combined_insert_string = ', '.join(combined_insert_string)\n",
    "\n",
    "        insert_string = 'INSERT INTO ' + final_df.columns[1] + '(' + combined_insert_string + ' ) VALUES(' + percent_s  + ')'\n",
    "        #print(insert_string)\n",
    "        df_columns = []\n",
    "        for i in range(len(final_df.columns)):\n",
    "            if(len(final_df.columns[i]) >= 64):\n",
    "                df_columns.append(final_df.columns[i][0:63])\n",
    "            else:\n",
    "                df_columns.append(final_df.columns[i]) \n",
    "\n",
    "        df_columns\n",
    "        for(row, rs) in final_df.iterrows():\n",
    "            for i in range(len(df_columns)):\n",
    "                # print(rs[i])\n",
    "                df_columns[i] = rs[i]\n",
    "                    \n",
    "            data = tuple(df_columns)\n",
    "            mycursor.execute(insert_string, data)\n",
    "            mydb.commit()\n",
    "        mydb.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Exceptio2344n', repr(e))\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856a0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
